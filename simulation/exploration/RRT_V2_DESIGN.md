# RRT Planner V2 - Design Document

## ğŸ“‹ ëª©í‘œ

1. **ë…¼ë¬¸ ì •í™•ì„±**: Section 4.1-4.2, Equations 8-22ë¥¼ ì •í™•íˆ êµ¬í˜„
2. **ì„±ëŠ¥ ìµœì í™”**: ê¸°ì¡´ ëŒ€ë¹„ 3-5ë°° ì†ë„ í–¥ìƒ
3. **í˜¸í™˜ì„±**: ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ì™€ 100% í˜¸í™˜
4. **ìœ ì§€ë³´ìˆ˜ì„±**: ëª…í™•í•œ ë¬¸ì„œí™” ë° í…ŒìŠ¤íŠ¸

---

## ğŸ“Š ê¸°ì¡´ ì½”ë“œ ë¶„ì„

### Input/Output ì¸í„°í˜ì´ìŠ¤

#### **ì…ë ¥ (`build_tree` ë©”ì„œë“œ)**
```python
def build_tree(
    root_pose: Pose2D,                      # í˜„ì¬ ë¡œë´‡ ìœ„ì¹˜
    sources: np.ndarray,                    # (N_s, 3) ì¶”ì •ëœ ì†ŒìŠ¤ë“¤
    observation_positions: np.ndarray,      # (N_o, 2) ê´€ì¸¡ ìœ„ì¹˜ë“¤
    observation_intensities: np.ndarray,    # (N_o,) ê´€ì¸¡ ê°•ë„ë“¤
    nearest_intensity_lookup: Callable,     # í•¨ìˆ˜: Pose2D -> (intensity, samples, distance)
    previous_best_branch: Optional[List[RRTNode]] = None
) -> Tuple[List[RRTNode], List[int]]       # (ë…¸ë“œ ë¦¬ìŠ¤íŠ¸, leaf ì¸ë±ìŠ¤ë“¤)
```

#### **ì¶œë ¥**
```python
# 1. nodes: List[RRTNode]
#    - RRT íŠ¸ë¦¬ì˜ ëª¨ë“  ë…¸ë“œ (ë£¨íŠ¸ í¬í•¨)
#    - ê° ë…¸ë“œëŠ” parent ì¸ë±ìŠ¤ë¥¼ í†µí•´ ì—°ê²°
#
# 2. leaves: List[int]
#    - Leaf ë…¸ë“œì˜ ì¸ë±ìŠ¤ë“¤
#    - ê²½ë¡œ ì„ íƒ ì‹œ ì´ ì¤‘ì—ì„œ ì„ íƒ

# select_best_branch() ì‚¬ìš©
best_branch, best_leaf_idx = planner.select_best_branch(nodes, leaves)
# best_branch: List[RRTNode] - ë£¨íŠ¸ë¶€í„° best leafê¹Œì§€ì˜ ê²½ë¡œ
```

#### **ë°ì´í„° êµ¬ì¡°**
```python
@dataclass(frozen=True)
class Pose2D:
    x: float
    y: float
    theta: float  # radians

    def as_array(self) -> np.ndarray:
        return np.array([self.x, self.y])

@dataclass
class RRTNode:
    pose: Pose2D
    parent: Optional[int]           # ë¶€ëª¨ ë…¸ë“œ ì¸ë±ìŠ¤
    step_length: float              # ë¶€ëª¨ë¡œë¶€í„°ì˜ ê±°ë¦¬
    cumulative_distance: float      # ë£¨íŠ¸ë¶€í„°ì˜ ëˆ„ì  ê±°ë¦¬
    cumulative_gain: float          # ë£¨íŠ¸ë¶€í„°ì˜ ëˆ„ì  gain
    node_gain: float                # ì´ ë…¸ë“œì˜ gain
    depth: int                      # íŠ¸ë¦¬ ê¹Šì´

@dataclass
class PlannerConfig:
    max_nodes: int = 80             # ìµœëŒ€ ë…¸ë“œ ìˆ˜
    n_uniform: int = 8              # ê· ì¼ ì´ˆê¸°í™” ê°œìˆ˜
    min_step: float = 8.0           # ìµœì†Œ step (í”½ì…€)
    max_step: float = 20.0          # ìµœëŒ€ step (í”½ì…€)
    random_seed: int = 42
```

---

## ğŸ› ì„±ëŠ¥ ë³‘ëª© ì§€ì 

### 1. **Nearest Neighbor ê²€ìƒ‰** (Line 366-410)
```python
# í˜„ì¬: O(n) ì„ í˜• ê²€ìƒ‰
tree_points = np.array([n.pose.as_array() for n in nodes])  # âš ï¸ ë§¤ë²ˆ ì¬ìƒì„±
nearest_idx = self._nearest_node(tree_points, sample)       # âš ï¸ O(n) ê²€ìƒ‰
```
**ë¬¸ì œ**:
- 80ê°œ ë…¸ë“œ Ã— 80ë²ˆ ë°˜ë³µ = 6,400íšŒ ê±°ë¦¬ ê³„ì‚°
- ë§¤ë²ˆ ë°°ì—´ ì¬ìƒì„±

**í•´ê²°ì±…**:
- KD-Tree ì‚¬ìš©: O(log n)
- ë˜ëŠ” ì ì§„ì  ë°°ì—´ ì—…ë°ì´íŠ¸

### 2. **Observation Lookup** (Line 429)
```python
nearest_intensity, samples_near, distance_near = nearest_intensity_lookup(pose)
```
**ë¬¸ì œ**:
- ëª¨ë“  observationê³¼ì˜ ê±°ë¦¬ ê³„ì‚° (O(n_obs))
- Iteration 15ì—ì„œ 15ê°œ obs Ã— 80 nodes = 1,200íšŒ

**í•´ê²°ì±…**:
- Observation windowing (ìµœëŒ€ 20ê°œ)
- KD-Tree for observations
- Caching

### 3. **Distance ê³„ì‚° ì¤‘ë³µ** (Line 432-435)
```python
if observation_positions.size > 0:
    distances = np.linalg.norm(observation_positions - pose.as_array()[None, :], axis=1)
```
**ë¬¸ì œ**:
- `nearest_intensity_lookup`ì—ì„œ ì´ë¯¸ ê³„ì‚°í–ˆëŠ”ë° ë˜ ê³„ì‚°

**í•´ê²°ì±…**:
- Lookup ê²°ê³¼ ì¬ì‚¬ìš©
- ê±°ë¦¬ ë°°ì—´ ìºì‹±

### 4. **ë°°ì—´ ë³µì‚¬ ì˜¤ë²„í—¤ë“œ**
```python
tree_points = np.array([n.pose.as_array() for n in nodes])  # ë§¤ë²ˆ ìƒì„±
```
**ë¬¸ì œ**:
- ë©”ëª¨ë¦¬ í• ë‹¹ ë° ë³µì‚¬ ë°˜ë³µ

**í•´ê²°ì±…**:
- Pre-allocated array + incremental update

---

## ğŸ¯ V2 ìµœì í™” ì „ëµ

### Strategy 1: **Spatial Indexing** (ìµœìš°ì„ )
```python
from scipy.spatial import cKDTree

class RRTPlannerV2:
    def __init__(self, ...):
        self._tree_points = np.zeros((max_nodes, 2))  # Pre-allocate
        self._n_nodes = 0
        self._kdtree = None

    def _add_node(self, node: RRTNode):
        self._tree_points[self._n_nodes] = node.pose.as_array()
        self._n_nodes += 1
        # Rebuild KD-tree periodically (every 10 nodes)
        if self._n_nodes % 10 == 0:
            self._kdtree = cKDTree(self._tree_points[:self._n_nodes])
```

**ì˜ˆìƒ ê°œì„ **: O(n) â†’ O(log n), **10-20ë°° ì†ë„ í–¥ìƒ**

### Strategy 2: **Observation Windowing + Caching**
```python
class RRTPlannerV2:
    def build_tree(self, ...):
        # Limit observations
        MAX_OBS = 20
        if len(observation_positions) > MAX_OBS:
            obs_positions = observation_positions[-MAX_OBS:]
            obs_intensities = observation_intensities[-MAX_OBS:]

        # Build KD-Tree for observations (once per iteration)
        obs_tree = cKDTree(obs_positions) if len(obs_positions) > 0 else None

        # Cache lookup results
        self._obs_cache = {}
```

**ì˜ˆìƒ ê°œì„ **: O(n_obs) â†’ O(log n_obs), **5-10ë°° ì†ë„ í–¥ìƒ**

### Strategy 3: **Vectorized Gain Computation**
```python
# í˜„ì¬: Loop over sources
for i, source in enumerate(sources):
    gain += self.single_source_gain(node_pos, source[:2])

# V2: Vectorized
def compute_total_gain_vectorized(self, node_pos: np.ndarray, sources: np.ndarray):
    # sources: (N_s, 3)
    distances = np.linalg.norm(sources[:, :2] - node_pos[None, :], axis=1)
    gains = self._vectorized_single_source_gain(distances)
    return np.sum(gains)
```

**ì˜ˆìƒ ê°œì„ **: **2-3ë°° ì†ë„ í–¥ìƒ**

### Strategy 4: **Early Stopping**
```python
# Max gainì— ë„ë‹¬í•˜ë©´ ì¡°ê¸° ì¢…ë£Œ
if len(leaves) > 0:
    best_gain = max(nodes[leaf].cumulative_gain for leaf in leaves)
    if best_gain > GAIN_THRESHOLD:  # ì¶©ë¶„íˆ ì¢‹ì€ ê²½ë¡œ ë°œê²¬
        break
```

**ì˜ˆìƒ ê°œì„ **: í‰ê·  **20-30% ë…¸ë“œ ê°ì†Œ**

### Strategy 5: **Lazy Evaluation**
```python
# Gain ê³„ì‚°ì„ í•„ìš”í•  ë•Œë§Œ ìˆ˜í–‰
class LazyRRTNode:
    def __init__(self, ...):
        self._gain = None

    @property
    def node_gain(self):
        if self._gain is None:
            self._gain = self._compute_gain()
        return self._gain
```

**ì˜ˆìƒ ê°œì„ **: **10-15% ì†ë„ í–¥ìƒ**

---

## ğŸ“ V2 êµ¬í˜„ ê³„íš

### Phase 1: í•µì‹¬ ìµœì í™” (í•„ìˆ˜)
1. âœ… Observation windowing (MAX_OBS=20)
2. âœ… KD-Tree for nearest neighbor search
3. âœ… KD-Tree for observation lookup
4. âœ… Pre-allocated arrays

### Phase 2: ì•Œê³ ë¦¬ì¦˜ ìµœì í™” (ê¶Œì¥)
5. âœ… Vectorized gain computation
6. âœ… Early stopping
7. âœ… Distance caching

### Phase 3: ê³ ê¸‰ ìµœì í™” (ì„ íƒ)
8. âš ï¸ Lazy evaluation
9. âš ï¸ Parallel gain computation
10. âš ï¸ Adaptive sampling

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì „ëµ

### 1. **Unit Tests**
```python
def test_nearest_neighbor():
    # KD-Tree vs Linear search ê²°ê³¼ ë¹„êµ

def test_gain_computation():
    # Vectorized vs Loop ê²°ê³¼ ë¹„êµ

def test_observation_windowing():
    # Windowed vs Full observations ë¹„êµ
```

### 2. **Integration Tests**
```python
def test_build_tree_compatibility():
    # V1ê³¼ V2ì˜ ì¶œë ¥ í˜•ì‹ ë¹„êµ
    # ê°™ì€ ì…ë ¥ â†’ ê°™ì€ í˜•ì‹ì˜ ì¶œë ¥

def test_with_explorer():
    # explorer_controllerì™€ í†µí•© í…ŒìŠ¤íŠ¸
```

### 3. **Performance Benchmarks**
```python
def benchmark_v1_vs_v2():
    # 1, 5, 10, 15 iterations ë¹„êµ
    # Time per iteration
    # Memory usage
```

### 4. **Visual Verification**
```python
def test_paper_correctness():
    # ë…¼ë¬¸ Figureì™€ ë¹„êµ
    # Gain ë¶„í¬ í™•ì¸
    # ê²½ë¡œ ì„ íƒ ê²€ì¦
```

---

## ğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ 

### í˜„ì¬ (V1)
```
Iteration  1: 0.064s
Iteration  5: 0.111s
Iteration 10: 0.274s
Iteration 15: 0.500s (ì˜ˆìƒ)
Total: ~3.5s
```

### ëª©í‘œ (V2)
```
Iteration  1: 0.020s  (3.2ë°° ë¹ ë¦„)
Iteration  5: 0.025s  (4.4ë°° ë¹ ë¦„)
Iteration 10: 0.030s  (9.1ë°° ë¹ ë¦„)
Iteration 15: 0.035s  (14.3ë°° ë¹ ë¦„)
Total: ~0.5s (7ë°° ë¹ ë¦„)
```

### ìµœì†Œ ëª©í‘œ
```
Total: <1.5s (2.3ë°° ì´ìƒ ê°œì„ )
ì¼ì •í•œ ì†ë„ ìœ ì§€ (max/min < 2.0)
```

---

## ğŸ”§ êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Priority 1 (Critical - ì£¼ë§ ë‚´)
- [x] Observation windowing
- [ ] KD-Tree nearest neighbor
- [ ] Pre-allocated arrays
- [ ] Basic compatibility tests

### Priority 2 (High - ë‹¤ìŒ ì£¼)
- [ ] KD-Tree observation lookup
- [ ] Vectorized gains
- [ ] Performance benchmarks
- [ ] Integration with explorer

### Priority 3 (Medium - ì—¬ìœ  ìˆì„ ë•Œ)
- [ ] Early stopping
- [ ] Distance caching
- [ ] Visual verification
- [ ] Documentation

### Priority 4 (Low - ì„ íƒì‚¬í•­)
- [ ] Lazy evaluation
- [ ] Parallel processing
- [ ] Adaptive sampling

---

## ğŸ“ API í˜¸í™˜ì„± ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] `Pose2D` ë™ì¼
- [ ] `RRTNode` ë™ì¼
- [ ] `PlannerConfig` ë™ì¼
- [ ] `build_tree()` ì‹œê·¸ë‹ˆì²˜ ë™ì¼
- [ ] `select_best_branch()` ì‹œê·¸ë‹ˆì²˜ ë™ì¼
- [ ] Return types ë™ì¼
- [ ] `explorer_controller.py` ìˆ˜ì • ì—†ì´ ì‘ë™

---

## ğŸ“ ë…¼ë¬¸ ë°©ì •ì‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Equation 8: Uniform Initialization
- [ ] n_uniformê°œ ê· ì¼ ë¶„í¬ ìƒì„±
- [ ] ê° ë°©í–¥ 2Ï€/n_uniform

### Equation 9: Branch Reuse
- [ ] ì´ì „ best branch ì¬ì‚¬ìš©
- [ ] Parent indices ì˜¬ë°”ë¥´ê²Œ ë§¤í•‘

### Equation 10: Node Pose
- [ ] ìƒˆ ë…¸ë“œ ìœ„ì¹˜ ê³„ì‚°
- [ ] Heading angle ê³„ì‚°

### Equations 11-16: Radiation Gain
- [ ] Single source gain (Eq. 11)
- [ ] Suppression factor (Eq. 13-14)
- [ ] Intensity correction (Eq. 15)
- [ ] Distance penalty (Eq. 16)

### Equations 17-19: Distance Gain
- [ ] Cumulative distance (Eq. 17)
- [ ] Heading change penalty (Eq. 18)
- [ ] g_dist ê³„ì‚° (Eq. 19)

### Equations 20-22: Entropy Gain
- [ ] Repeat exploring correction (Eq. 21)
- [ ] Redundant sampling correction (Eq. 22)
- [ ] g_entropy ê³„ì‚° (Eq. 20)

---

## ğŸš€ Next Steps

1. **ì§€ê¸ˆ ë‹¹ì¥**: Observation windowing í™•ì¸ (ì´ë¯¸ ì ìš©ë¨)
2. **ì˜¤ëŠ˜**: KD-Tree nearest neighbor êµ¬í˜„
3. **ë‚´ì¼**: ì „ì²´ RRTPlannerV2 í´ë˜ìŠ¤ ì‘ì„±
4. **ëª¨ë ˆ**: í…ŒìŠ¤íŠ¸ ë° ë²¤ì¹˜ë§ˆí¬
5. **ì£¼ë§**: í†µí•© ë° ê²€ì¦

---

## ğŸ“š ì°¸ê³  ìë£Œ

- **Original File**: `simulation/exploration/rrt_planner.py`
- **Usage**: `visualization/explorer_controller.py` line 522
- **Paper**: Section 4.1-4.2, Equations 8-22
- **Performance Analysis**: `visualization/PERFORMANCE_FIX.md`
